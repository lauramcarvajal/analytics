title: Topics on Multiple Linear Regression 
output:
  html_document: default
---

Load in any required packages here
```{r loadingPackages}
require(dplyr)
require(caret)
require(doParallel)
```

Refer to '2018flights.Rdata'.  Either change the pathname in the load statement or copy the file to the directory where this Rmd file resides..

```{r loadData}
load("2018flights.Rdata")
flightsNotCancelled = df %>%
  filter(CANCELLED == 0) %>% 
  na.omit
```

To speed up some computations for the purposes of this exercise, subsampling from flight database of flights..

```{r subsample}
set.seed(1)
nTotal = nrow(flightsNotCancelled)
flightsNotCancelled = flightsNotCancelled[sample(1:nTotal,round(nTotal/2)),]

# Cleaning up the name space to free up memory
rm(df)
```

# Part 1 - The bootstrap

To estimate the difference in the mean 'arrival delay' of flights between the winter and the summer, we'll define October through March as the winter and April through September the summer...


#The normality assumption - apply the classic "pooled two sample t-test" for testing the population means between two groups. Obtain the sample means for these two groups, the sample variances for each group, and the sample size for each group

```{r samplemean}

winter = flightsNotCancelled %>% 
  filter(MONTH >= 10 | MONTH <= 3) %>% 
  summarise(mean = mean(ARR_DELAY), var = var(ARR_DELAY), n = n())
summer = flightsNotCancelled %>% 
  filter(MONTH >= 4 | MONTH <= 9) %>%
  summarise(mean = mean(ARR_DELAY), var = var(ARR_DELAY), n = n()) 


```

#### The sample mean difference between winter and summer is -3.3672665, -320.1140984, -215386

### Getting the pooled sample variance and the quantile from the t-distribution, we can get the pooled two-sample 
t-test confidence interval

```{r pooledttest}
winterMinusSummer = winter$mean - summer$mean
n                 = winter$n + summer$n
pooledVar         = ((winter$n - 1)*winter$var + (summer$n - 1)*summer$var)/(n - 2)
tQuantile         = qt(1-0.05/2,n-2)

winterMinusSummerSE = sqrt(pooledVar)*sqrt(1/winter$n + 1/summer$n)
normalCI            = c(winterMinusSummer - tQuantile * winterMinusSummerSE,
                        winterMinusSummer + tQuantile * winterMinusSummerSE)
```

#### The CI is 95% with interval endpoints of (`r normalCI[1]`, `r normalCI[2]`)
####The estimated winter mean delay is (`r winterMinusSummer`) shorter than the mean summer delay

## Using bootstrap, let's do 10 bootstrap draws and compare the confidence interval...

```{r bootstrapSequential, cache = TRUE}
nBootstrapDraws = 10

bootstrapResults = rep(0,nBootstrapDraws)
srt = proc.time()[3]
for(b in 1:nBootstrapDraws){
  flightsNotCancelled_boot = flightsNotCancelled[sample(1:n,n,replace=TRUE), ]  

  
  bootstrapResults[b] = winter$mean - summer$mean 
  
end = proc.time()[3]
totalTimeSeq = end - srt
totalTimeSeq 

bootstrapCI = bootstrapCI = c(quantile(bootstrapResults,probs = 0.025), 
               quantile(bootstrapResults,probs = 0.975))


#housekeeping
rm(flightsNotCancelled_boot)
```

A 95% bootstrap confidence interval would be (`r bootstrapCI[1]`, `r bootstrapCI[2]`).  This took 
`r totalTimeSeq` seconds to compute.

Parallelize this so that it will run faster

```{r ncores}
nCores = detectCores()
nCores
```
This system has `r nCores` cores.  However, the data set takes up a fair amount of memory

```{r memory}
format(object.size( flightsNotCancelled ),units='MB')
```

re-require(dplyr) inside the parallel call due to the fact that a new R session is created at each core.

```{r bootstrapParallel, cache = TRUE}
cl = makeCluster(3)
registerDoParallel(cl)

nBootstrapDraws = 10

bootstrapResults = rep(0,nBootstrapDraws)

srt = proc.time()[3]
foreach(k = 1:nBootstrapDraws) %dopar% 
   require(dplyr)
  flightsNotCancelled_boot = flightsNotCancelled[sample(1:n,n,replace=TRUE), ]  
  winter = flightsNotCancelled_boot %>% 
    filter(MONTH >= 10 | MONTH <= 3) %>% 
    summarise(mean = mean(ARR_DELAY))
  summer = flightsNotCancelled_boot %>% 
    filter(MONTH >= 4 | MONTH <= 9) %>% 
    summarise(mean = mean(ARR_DELAY)) 
  
  bootstrapResults[b] = winter["mean"] - summer["mean"]
}
end = proc.time()[3]

totalTimePar = end - srt

totalTimePar

stopCluster(cl)
registerDoSEQ()# This returns the session to "serial" instead of "parallel"
```

This took `r totalTimePar` seconds to compute.

```{r problem2}
rm(list=ls())# housekeeping

load("2018flights.Rdata")
flightsNotCancelled = df %>%
  filter(CANCELLED == 0) %>%
  select(OP_UNIQUE_CARRIER, MONTH, DEP_DELAY) %>%
  mutate(MONTH = as.factor(MONTH),OP_UNIQUE_CARRIER = as.factor(OP_UNIQUE_CARRIER))

set.seed(1)
nTotal              = nrow(flightsNotCancelled)
flightsNotCancelled = flightsNotCancelled[sample(1:nTotal,round(nTotal/2)),]

apply(flightsNotCancelled,2,anyNA)

# Clean up the name space to free up memory
rm(df)
```

```{r problem21filter}
flightsNeedPrediction = flightsNotCancelled %>%
  filter(is.na(DEP_DELAY)) %>%
  select(-DEP_DELAY)
flights               = flightsNotCancelled %>%
  filter(!is.na(DEP_DELAY))
```

## Obtain training/test split for evaluating our regression model's performance.  Splitting into 25% train and 75% test, making sure the proportions of flights per months is approximately equal between the two subsets. 

```{r split}
training = createDataPartition(flights$MONTH, p = .25, list = FALSE)
train    = flights[ training,] 
test     = flights[-training,] 
```

## 2.2. Dummy variables

Converting the factor features to numeric ones via dummy variables. After fitting, the supervisor was transformed logarithmically due to heavy skew when looking at the residual plots... 

```{r dummy}
dummyVarsX = dummyVars(~ OP_UNIQUE_CARRIER + MONTH, data = train, fullRank = TRUE) 
dummyVarsX
Xtrain = predict(dummyVarsX, train)
Xtest  = predict(dummyVarsX, test) 
Ytrain = log(train$DEP_DELAY+123)
Ytest  = log(test$DEP_DELAY+123) 
```
Dummy Variable Object

Formula: ~OP_UNIQUE_CARRIER + MONTH
2 variables, 2 factors
Variables and levels will be separated by '.'
A full rank encoding is used


## 2.3. Fitting the model - We will additionally record the 2-Fold CV estimate of the test error so we can compare to the test error (2-fold, again, for computational reasons).

```{r train}
trainControlOut = trainControl(method = 'cv', number = 2)
lmOut           = train(Xtrain, Ytrain, method="lm",
                        trControl = trainControlOut)
```

Look at the residuals in any multiple regression application to see if we a missing any structure. Compute and plot the residuals:

```{r residuals}
YhatTrain = predict(lmOut, newdata = Xtrain)
residuals = Ytrain - YhatTrain 
plot(YhatTrain,residuals)
```

#### The plot shows positively skewed residuals but seemingly clustered around the mean, with the exception of a few outliers; obtaining predictions on the test data and computing

* the apparent error estimate of the test loss 
* the CV estimate of the test loss
* the test loss

(use the mean loss instead of sum in each case)

```{r test}
YhatTest      = predict(lmOut, newdata = Xtest)

apparentError = mean( (YhatTrain - Ytrain)**2 ) 
CVloss        = mean( lmOut$resample$RMSE**2 ) 
testLoss      = mean( (YhatTest - Ytest)**2 ) 
```

The apparent error estimate of the test loss is `r apparentError`, the CV estimate of the test loss is `r CVloss`, and the test loss is `r testLoss`.


## Predict the NA

Predicting the flights that don't have the DEP_DELAY listed.  Using the above process to transform the observations in 'flightsNeedPrediction' to use our model to get the predictions.  To transform the model predicted DEP_DELAY back to the original scale (it is on log(x + 123), applying the inverse: exp(y) - 123

```{r prediction}
Xprediction  = predict(dummyVarsX, flightsNeedPrediction) 
Yhat         = predict(lmOut, newdata = Xprediction) 
DEP_DELAYhat = exp(Yhat) - 123
```

Compare the means by MONTH between the flightsNeedPrediction and flights observations

```{r comparison}
flights %>% 
  group_by(MONTH) %>% 
  summarise(mean = mean(DEP_DELAY))

cbind(flightsNeedPrediction,DEP_DELAYhat) %>% 
  group_by(MONTH) %>% 
  summarise(mean=mean(DEP_DELAYhat))
```

#### 


Note that the flightsNeedPrediction observations came entirely from Months 1-8 and we predict they would have had lower mean delay time than the flights in ‘flights’.


## Looking at the coefficient estimates.  Because we transformed the supervisor, that complicates interpretting the coefficients themselves.  However, we can still look at which airline has the worst delays by looking for the largest, significant coefficient (define significant here to mean p-value less than 0.05)

```{r coeffest}
betaHat = summary(lmOut)$coefficients
betaHatAirline = betaHat[grep('OP',row.names(betaHat)),]
betaHatAirline[which.max(betaHatAirline[,1]),]
betaHatAirline
```

#### After accounting for the effects of month, we estimate that the airline with the longest delays is ‘F9’
